import streamlit as st
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns  
import datetime
import gdown

#Import des biblioth√®ques ML
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler

from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error

from sklearn.model_selection import TimeSeriesSplit
from sklearn.model_selection import GridSearchCV
from prophet import Prophet


def intro():
    # ==========================================================================
    # Initialisation des cl√©s de session_state pour tous les mod√®les et donn√©es
    # ==========================================================================
    if 'df' not in st.session_state:
        st.session_state['df'] = None
        st.session_state['split_date'] = None
        st.session_state['target'] = None
        st.session_state['features'] = None
        st.session_state['rf_metrics_per_region'] = None
        st.session_state['rf_global_mean_metrics'] = None
        st.session_state['xgb_metrics_per_region'] = None
        st.session_state['xgb_global_mean_metrics'] = None

    st.write('## Classification du probl√®me üìÇ')
    st.write("");st.write("") 

    st.markdown(""" <u>Type de probl√®me et t√¢che de machine learning</u> : 
            Notre projet s‚Äôapparente √† de la **pr√©diction de valeurs continues dans une suite temporelle** pr√©sentant plusieurs saisonnalit√©s.
                L'objectif est d'anticiper la demande en √©nergie en fonction du temps, des conditions m√©t√©orologiques et d'autres facteurs exog√®nes.
                """,unsafe_allow_html=True)
    st.write('#### Choix des m√©triques de performance üéØ')
            
    st.markdown("""La m√©trique **MAPE (Mean Absolute Percentage Error)** est notre m√©trique principale car elle est facilement interpr√©table et comparable avec d‚Äôautres mod√®les.
                Nous cherchons d‚Äôune part √† p√©naliser les grandes erreurs compte tenu de l‚Äôenjeu de pr√©diction de consommation au plus juste (**RMSE** faible), 
                tout en pouvant comparer facilement nos diff√©rents mod√®les sur la base de % de variation (MAPE). Enfin, la qualit√© globale du mod√®le doit aussi √™tre √©lev√©e pour tenir compte de mani√®re √©quilibr√©e des sp√©cificit√©s r√©gionales (**Score R2**).""") 
    st.markdown("""
                Pour couvrir l‚Äôensemble des KPI pertinents sur ce probl√®me de r√©gression nous allons donc r√©cup√©rer chacun des indicateurs type :
                
                - Erreurs absolues et relatives (**MAE, MAPE**)
                - Erreurs quadratiques (**MSE, RMSE**)
                - Qualit√© d‚Äôajustement (**R¬≤ Score**)
                """)
    st.write('#### Choix des mod√®les Machine Learning ü§ñ ')
    st.markdown("""
                De fa√ßon plus limit√©e que le rapport d'√©tude, nous ne pr√©senterons ici que :

                - <span style="color:blue;">**Prophet**</span> : pour challenger notamment la d√©tection des saisonnalit√©s et la robustesse √† long terme.
                - <span style="color:blue;">**RandomForest**</span>, <span style="color:blue;">**XG Boost**</span> : 2 autres mod√®les, plus g√©n√©ralistes et simples √† entra√Æner

                Ces mod√®les sont connus pour bien g√©rer les s√©ries temporelles.
                """, unsafe_allow_html=True)
    st.write('#### Series temporelles (hold-out)‚è≤Ô∏è, encodage, standardisation ? ‚Äù')
    st.markdown("""
                Objectif = √âviter la fuite de donn√©es. Si les donn√©es ne sont pas tri√©es par date et que le train_test_split est al√©atoire, 
                il est possible que des observations tr√®s proches temporellement se r√©partissent entre Train et Test faussant l'entra√Ænement. 
                En triant par date, les donn√©es de test et en ‚Äòsplitant‚Äô sur la fin du jeu de donn√©es, les donn√©es de Test sont vraiment "in√©dites" pour le mod√®le. 
                """)
    st.markdown(""" Avec **Random Forest**, **XGBoost** et **Prophet**, l‚Äôencodage n'apporte pas de b√©n√©fices majeurs par rapport √† une simple variable cat√©gorielle (ex. hour ou dayofweek). 
                De m√™me, la normalisation des donn√©es n‚Äôa pas d‚Äôimpact significatif sur la performance des mod√®les. Nous faisons le choix de laisser les variables sans normalisation et sans transformation variables cycliques.
            """)
    
    st.write('#### Fine tunning - Hyperparam√®tres ')
    st.write("Pour une approche plus m√©thodique dans la comparaison des 2 mod√®les bas√©s sur des arbres de d√©cisions et travailler avec les meilleurs param√®trages, " \
    "nous avons utilis√© **Grid Search**. Pour all√©ger le besoin de puissance de calcul demand√©s ci-apr√®s, nous laisserons laisserons les param√®tres suivants."
    "C'est un compromis entre une exigence de m√©moire acceptable pour ce projet streamlit en ligne et des score √©lev√©s des m√©triques observ√©es ")
    
    code = '''
            current_model = RandomForestRegressor(
                n_estimators=8, # Nombre d'arbres dans la for√™t. Plus il y en a, plus le mod√®le est robuste mais lent.
                max_depth=8, # Profondeur maximale de chaque arbre. Contr√¥le la complexit√© du mod√®le pour √©viter le surapprentissage.
                min_samples_split=2, # Nombre minimum d'√©chantillons requis pour diviser un n≈ìud interne.
                min_samples_leaf=1, # Nombre minimum d'√©chantillons requis pour qu'un n≈ìud soit une feuille.
                random_state=42, # Graine al√©atoire pour la reproductibilit√© des r√©sultats.
                n_jobs=1 # Utile pour Streamlit pour la performance

            current_model = XGBRegressor(
                n_estimators=100,    # Nombre d'estimateurs (arbres)
                max_depth=3,         # Profondeur maximale de l'arbre
                learning_rate=0.05,  # Taux d'apprentissage. R√©duit la contribution de chaque arbre pour rendre le mod√®le plus robuste.
                random_state=42,
                n_jobs=1 
            )
        '''
    st.code(code, language='python')

def lancement():
    # Bouton pour lancer le traitement des donn√©es et l'affichage
    if st.button("Charger et Traiter les Donn√©es"):
        with st.spinner("Chargement et traitement des donn√©es en cours..."):
            # Assignation directe √† 'df' et stockage sous la cl√© 'df' dans session_state
            df, split_date, target, features = load_process_dataset_modelisation() 
            
            st.session_state['df'] = df
            st.session_state['split_date'] = split_date
            st.session_state['target'] = target
            st.session_state['features'] = features
 
        st.success("Donn√©es charg√©es et pr√©trait√©es avec succ√®s !")
        
        st.subheader("Aper√ßu du DataFrame apr√®s pr√©traitement :")
        st.dataframe(st.session_state['df'].sample(10)) 
        
        st.subheader("Param√®tres de mod√©lisation :")
        st.write(f"**Date de s√©paration (split_date) :** {st.session_state['split_date']}")
        st.write(f"**Variable cible (target) :** `{st.session_state['target']}`")
        st.write(f"**Variables explicatives (features) :**")
        st.write(st.session_state['features'])

    # ======================================================================
    # Nouveau bouton pour entra√Æner RF et XGBoost ensemble
    # ======================================================================
    # V√©rifie si les donn√©es sont charg√©es avant d'afficher ce bouton
    if st.session_state['df'] is not None: 
        if st.button("Lancer l'entra√Ænement et l'√©valuation des mod√®les (RF & XGBoost)"):
            # R√©cup√©rer les donn√©es de session_state pour les passer √† la fonction RF_XGB
            df = st.session_state['df'] 
            split_date = st.session_state['split_date']
            target = st.session_state['target']
            features = st.session_state['features']

            # --- Entra√Ænement et √©valuation RandomForest ---
            with st.spinner("Entra√Ænement et √©valuation du mod√®le RandomForest en cours..."):
                # Appel de la fonction renomm√©e RF_XGB pour RandomForest
                rf_metrics_df_per_region, rf_global_mean_metrics = RF_XGB("RandomForest", df, split_date, target, features)
                
                st.session_state['rf_metrics_per_region'] = rf_metrics_df_per_region
                st.session_state['rf_global_mean_metrics'] = rf_global_mean_metrics
            st.success("√âvaluation RandomForest termin√©e !")
            
            st.markdown("---") # S√©parateur visuel entre les mod√®les

            # --- Entra√Ænement et √©valuation XGBoost ---
            with st.spinner("Entra√Ænement et √©valuation du mod√®le XGBoost en cours..."):
                # Appel de la fonction renomm√©e RF_XGB pour XGBoost
                xgb_metrics_df_per_region, xgb_global_mean_metrics = RF_XGB("XGBoost", df, split_date, target, features)

                st.session_state['xgb_metrics_per_region'] = xgb_metrics_df_per_region
                st.session_state['xgb_global_mean_metrics'] = xgb_global_mean_metrics
            st.success("√âvaluation XGBoost termin√©e !")
        
        # ======================================================================
        # Affichage s√©par√© des r√©sultats RF et XGBoost
        # Ces blocs s'ex√©cutent si les r√©sultats sont pr√©sents dans session_state
        # ======================================================================
        if st.session_state['rf_metrics_per_region'] is not None:
            st.subheader("Performances du mod√®le RandomForest par r√©gion :")
            st.dataframe(st.session_state['rf_metrics_per_region'].set_index('R√©gion').style.highlight_max(axis=0, subset=['R2 Score']).highlight_min(axis=0, subset=['Mean Absolute Error', 'MAPE (%)', 'Root Mean Squared Error', 'Bias']))

            st.subheader("Moyennes des m√©triques d'√©valuation RandomForest (Global) :")
            st.dataframe(st.session_state['rf_global_mean_metrics'].to_frame(name='Moyenne').T)

        if st.session_state['xgb_metrics_per_region'] is not None:
            st.markdown("---") 
            st.subheader("Performances du mod√®le XGBoost par r√©gion :")
            st.dataframe(st.session_state['xgb_metrics_per_region'].set_index('R√©gion').style.highlight_max(axis=0, subset=['R2 Score']).highlight_min(axis=0, subset=['Mean Absolute Error', 'MAPE (%)', 'Root Mean Squared Error', 'Bias']))

            st.subheader("Moyennes des m√©triques d'√©valuation XGBoost (Global) :")
            st.dataframe(st.session_state['xgb_global_mean_metrics'].to_frame(name='Moyenne').T)
    else:
        st.info("Cliquez sur 'Charger et Traiter les Donn√©es' pour commencer √† visualiser et mod√©liser. " \
        "L'entrainement des mod√®les est ensuite propos√©.")

@st.cache_data    
def load_process_dataset_modelisation():
    #T√©l√©charge et pr√©traite les donn√©es depuis Google Drive."""
    file_id = "1dunWvb7loR5kWYZwb8BX_lwmYMP0157q"  # Ton ID de fichier extrait
    url = f"https://drive.google.com/uc?id={file_id}"  # Lien de t√©l√©chargement direct
    output = "COMPILATION_CONSO_TEMP_POP_reduced.csv"
    
    try:
        gdown.download(url, output, quiet=False)
    except Exception as e:
        st.error(f"Erreur lors du t√©l√©chargement du fichier : {e}")
        st.stop() 

    df= pd.read_csv(output, sep=';', on_bad_lines="skip", encoding="utf-8",low_memory=False)
    
    # Remettre la colonne 'Date + Heure' en index
    df['Date + Heure'] = pd.to_datetime(df['Date + Heure'], errors='coerce')  # g√©rer les erreurs
    df = df.set_index('Date + Heure')
    df = df.sort_index()  # utile pour resample()

    # Conversion en datetime DATE pour extractions 
    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d', errors='coerce')
    # Extraire les caract√©ristiques temporelles SUPPLEMENTAIRES √† partir de 'DATE'
    df['year'] = df['Date'].dt.year
    df['month'] = df['Date'].dt.month
    df['day_of_week'] = df['Date'].dt.dayofweek  # Lundi = 0, Dimanche = 6
    df['day_of_year'] = df['Date'].dt.dayofyear
    df['week_of_year'] = df['Date'].dt.isocalendar().week
    df['PlageHoraire']= df['Heure']
    #df['PlageHoraire']= df['Heure'].str[:2].astype(int) # Extraction de l'heure
    df = df.drop(columns=['Date', 'Heure'])

    # R√©cup√©rer toutes les colonnes du DataFrame
    all_columns = df.columns.tolist()

    # D√©finir la target (√† exclure des features)
    target = 'Consommation (MW)'

    # D√©finir une liste de colonnes √† exclure (en plus de la target)
    exclude_columns = ['R√©gion']

    # S√©lectionner les features en excluant la target et les colonnes √† exclure
    features = [col for col in all_columns if col != target and col not in exclude_columns]

    # D√©finir la proportion de l'ensemble de test
    test_size = 0.20  # Pour 20%
    # Calculer la date de s√©paration
    split_date = df.iloc[int(len(df) * (1 - test_size))].name
    # Afficher la date de s√©paration
    print(f"Date de s√©paration pour {int(test_size * 100)}% de test : {split_date}")

    return df, split_date, target, features


def RF_XGB(model_name, df, split_date, target, features):
    """
    Entra√Æne un mod√®le (RandomForest ou XGBoost) pour chaque r√©gion et √©value ses performances.
    Args:
        model_name (str): Nom du mod√®le √† entra√Æner ("RandomForest" ou "XGBoost").
        df (pd.DataFrame): DataFrame contenant les donn√©es pr√©trait√©es.
        split_date (datetime): Date de s√©paration pour les ensembles d'entra√Ænement/test.
        target (str): Nom de la colonne cible.
        features (list): Liste des noms des colonnes explicatives.
    Returns:
        tuple: DataFrame des m√©triques par r√©gion et Series des m√©triques moyennes globales.
    """
    results = []
    regions = df['R√©gion'].unique()

    # Diviser le DataFrame global en ensembles d'entra√Ænement et de test une seule fois
    train_df = df[df.index < split_date]
    test_df = df[df.index >= split_date]

    for region in regions:
        st.write(f"Entra√Ænement et √©valuation du mod√®le **{model_name}** pour la r√©gion : **{region}**") 
        
        # Filtrer les donn√©es par r√©gion √† partir des ensembles d√©j√† splitt√©s
        train_region_df = train_df[train_df['R√©gion'] == region]
        test_region_df = test_df[test_df['R√©gion'] == region]
            
        X_train = train_region_df[features]
        y_train = train_region_df[target]
        X_test = test_region_df[features]
        y_test = test_region_df[target]

        # =========================================
        # INSTANCIATION DU MOD√àLE + HYPERPARAM√àTRES
        # =========================================
        current_model = None
        if model_name == "RandomForest":
            current_model = RandomForestRegressor(
                n_estimators=8, # Nombre d'arbres dans la for√™t. Plus il y en a, plus le mod√®le est robuste mais lent.
                max_depth=8, # Profondeur maximale de chaque arbre. Contr√¥le la complexit√© du mod√®le pour √©viter le surapprentissage.
                min_samples_split=2, # Nombre minimum d'√©chantillons requis pour diviser un n≈ìud interne.
                min_samples_leaf=1, # Nombre minimum d'√©chantillons requis pour qu'un n≈ìud soit une feuille.
                random_state=42, # Graine al√©atoire pour la reproductibilit√© des r√©sultats.
                n_jobs=1 # Utile pour Streamlit pour la performance
            )
        elif model_name == "XGBoost":
            current_model = XGBRegressor(
                n_estimators=100,    # Nombre d'estimateurs (arbres)
                max_depth=3,         # Profondeur maximale de l'arbre
                learning_rate=0.05,  # Taux d'apprentissage. R√©duit la contribution de chaque arbre pour rendre le mod√®le plus robuste.
                random_state=42,
                n_jobs=1 
            )
        else:
            st.error(f"Mod√®le non support√© pour l'entra√Ænement : {model_name}")
            continue 
        
        current_model.fit(X_train, y_train)

        predictions = current_model.predict(X_test)
        
        # Calculer les m√©triques
        mse = mean_squared_error(y_test, predictions)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, predictions)
        mape = mean_absolute_percentage_error(y_test, predictions) * 100 
        r2 = r2_score(y_test, predictions)
        
        # Moyennes des valeurs r√©elles et pr√©dites
        mean_y_test = np.mean(y_test)
        mean_y_pred = np.mean(predictions) 
        # Calcul du Bias
        bias = mean_y_pred - mean_y_test

        result = {
            'R√©gion': region,
            'Moy y_test': mean_y_test,
            'Moy y_pred': mean_y_pred,
            'Bias': bias,
            'Mean Squared Error': mse,
            'Root Mean Squared Error': rmse,
            'Mean Absolute Error': mae,
            'MAPE (%)': mape, 
            'R2 Score': r2
        }
        
        # Ajouter les importances des features si le mod√®le le supporte
        if hasattr(current_model, 'feature_importances_'):
            for feature, importance in zip(X_train.columns, current_model.feature_importances_): 
                result[f'Importance {feature}'] = importance
        
        results.append(result)
        
    results_df = pd.DataFrame(results)
    
    # Calculer la moyenne des m√©triques globales (pour toutes les r√©gions)
    numeric_metrics_cols = ['R2 Score', 'Mean Squared Error', 'Root Mean Squared Error', 'Mean Absolute Error', 'MAPE (%)', 'Bias']
    mean_metrics = results_df[numeric_metrics_cols].mean()

    return results_df, mean_metrics

