import streamlit as st
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns  
import datetime
import gdown
import plotly.graph_objects as go
import plotly.express as px

#Import des biblioth√®ques ML
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler

from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error

from sklearn.model_selection import TimeSeriesSplit
from sklearn.model_selection import GridSearchCV
from prophet import Prophet

def plot_date_order(df_to_check, title="V√©rification de l'ordre temporel du DataFrame"):
    """
    Cr√©e un nuage de points pour v√©rifier l'ordre temporel d'un DataFrame.
    L'axe X est l'index (date), l'axe Y est la position ordinale.
    """
    if not isinstance(df_to_check.index, pd.DatetimeIndex):
        st.warning("L'index du DataFrame n'est pas de type DatetimeIndex. La v√©rification peut √™tre impr√©cise.")
        return

    # Cr√©er une colonne pour la position ordinale
    df_to_check['ordinal_position'] = range(len(df_to_check))

    fig = px.scatter(df_to_check,
                     x=df_to_check.index,
                     y='ordinal_position',
                     title=title,
                     labels={'x': 'Date de l\'Index', 'ordinal_position': 'Position Ordinale dans le DataFrame'},
                     template="plotly_white")
    
    if 'split_date' in st.session_state and st.session_state['split_date'] is not None:
        try:
            split_date_dt = pd.to_datetime(st.session_state['split_date'])
            split_idx_pos = df_to_check.index.get_loc(split_date_dt, method='nearest')
            if isinstance(split_idx_pos, slice):
                split_idx_pos = split_idx_pos.start if split_idx_pos.start is not None else 0

            fig.add_vline(x=split_date_dt, line_width=2, line_dash="dash", line_color="red",
                          annotation_text=f"Split Date: {split_date_dt.strftime('%Y-%m-%d %H:%M')}",
                          annotation_position="top right")
            
            if split_date_dt in df_to_check.index:
                position_at_split = df_to_check.loc[split_date_dt]['ordinal_position']
                if isinstance(position_at_split, pd.Series):
                    position_at_split = position_at_split.iloc[0]
                
                fig.add_hline(y=position_at_split, 
                              line_width=2, line_dash="dash", line_color="blue",
                              annotation_text=f"Position: {split_idx_pos}",
                              annotation_position="bottom right")

        except Exception as e:
            st.warning(f"Impossible d'ajouter la split_date au graphique: {e}")

    fig.update_layout(hovermode="x unified")
    st.plotly_chart(fig, use_container_width=True)
    df_to_check.drop(columns=['ordinal_position'], inplace=True, errors='ignore')

def plot_target_over_time_with_split(df_to_check, target_col, split_date, title="Visualisation de la s√©rie temporelle et du point de s√©paration"):
    """
    Trace la variable cible sur l'index de temps et marque la date de s√©paration.
    Affiche une portion des donn√©es pour une meilleure lisibilit√©.
    """
    if not isinstance(df_to_check.index, pd.DatetimeIndex):
        st.warning("L'index du DataFrame n'est pas de type DatetimeIndex.")
        return

    # Pour √©viter de tracer un DataFrame trop grand (lent), on peut prendre un √©chantillon ou une p√©riode limit√©e.
    # Par exemple, les derni√®res 3 ann√©es ou un √©chantillon stratifi√©
    # Si le DataFrame est tr√®s grand, prenez un √©chantillon repr√©sentatif ou une sous-p√©riode
    df_sample = df_to_check.tail(365 * 24 * 3) # Ex: les 3 derni√®res ann√©es d'heures

    fig = go.Figure()

    fig.add_trace(go.Scatter(x=df_sample.index, y=df_sample[target_col], mode='lines', name=target_col))

    fig.update_layout(title=title,
                      xaxis_title="Date",
                      yaxis_title=target_col,
                      template="plotly_white")

    # Ajouter une ligne verticale pour marquer la split_date
    if split_date:
        fig.add_vline(x=split_date, line_width=2, line_dash="dash", line_color="red",
                      annotation_text=f"Date de S√©paration: {split_date.strftime('%Y-%m-%d %H:%M')}",
                      annotation_position="top right")

    st.plotly_chart(fig, use_container_width=True)

# Exemple d'utilisation dans votre `lancement()`:
# Juste apr√®s que st.session_state['df'] et split_date soient mis √† jour
# if st.session_state['df'] is not None and st.session_state['split_date'] is not None:
#     st.subheader("Visualisation de la variable cible par rapport au temps")
#     plot_target_over_time_with_split(st.session_state['df'], 
#                                       st.session_state['target'], 
#                                       st.session_state['split_date'])

def intro():
    # ==========================================================================
    # Initialisation des cl√©s de session_state pour tous les mod√®les et donn√©es
    # ==========================================================================
    if 'df' not in st.session_state:
        st.session_state['df'] = None
        st.session_state['split_date'] = None
        st.session_state['target'] = None
        st.session_state['features'] = None
        st.session_state['rf_metrics_per_region'] = None
        st.session_state['rf_global_mean_metrics'] = None
        st.session_state['xgb_metrics_per_region'] = None
        st.session_state['xgb_global_mean_metrics'] = None

    st.write('## Classification du probl√®me üìÇ')
    st.write("");st.write("") 

    st.markdown(""" <u>Type de probl√®me et t√¢che de machine learning</u> : 
            Notre projet s‚Äôapparente √† de la **pr√©diction de valeurs continues dans une suite temporelle** pr√©sentant plusieurs saisonnalit√©s.
                L'objectif est d'anticiper la demande en √©nergie en fonction du temps, des conditions m√©t√©orologiques et d'autres facteurs exog√®nes.
                """,unsafe_allow_html=True)
    st.write('#### Choix des m√©triques de performance üéØ')
            
    st.markdown("""La m√©trique **MAPE (Mean Absolute Percentage Error)** est notre m√©trique principale car elle est facilement interpr√©table et comparable avec d‚Äôautres mod√®les.
                Nous cherchons d‚Äôune part √† p√©naliser les grandes erreurs compte tenu de l‚Äôenjeu de pr√©diction de consommation au plus juste (**RMSE** faible), 
                tout en pouvant comparer facilement nos diff√©rents mod√®les sur la base de % de variation (MAPE). Enfin, la qualit√© globale du mod√®le doit aussi √™tre √©lev√©e pour tenir compte de mani√®re √©quilibr√©e des sp√©cificit√©s r√©gionales (**Score R2**).""") 
    st.markdown("""
                Pour couvrir l‚Äôensemble des KPI pertinents sur ce probl√®me de r√©gression nous allons donc r√©cup√©rer chacun des indicateurs type :
                
                - Erreurs absolues et relatives (**MAE, MAPE**)
                - Erreurs quadratiques (**MSE, RMSE**)
                - Qualit√© d‚Äôajustement (**R¬≤ Score**)
                """)
    st.write('#### Choix des mod√®les Machine Learning ü§ñ ')
    st.markdown("""
                De fa√ßon plus limit√©e que le rapport d'√©tude, nous ne pr√©senterons ici que :

                - <span style="color:blue;">**Prophet**</span> : pour challenger notamment la d√©tection des saisonnalit√©s et la robustesse √† long terme.
                - <span style="color:blue;">**RandomForest**</span>, <span style="color:blue;">**XG Boost**</span> : 2 autres mod√®les, plus g√©n√©ralistes et simples √† entra√Æner

                Ces mod√®les sont connus pour bien g√©rer les s√©ries temporelles.
                """, unsafe_allow_html=True)
    st.write('#### Series temporelles (hold-out)‚è≤Ô∏è, encodage, standardisation ? ‚Äù')
    st.markdown("""
                Objectif = √âviter la fuite de donn√©es. Si les donn√©es ne sont pas tri√©es par date et que le train_test_split est al√©atoire, 
                il est possible que des observations tr√®s proches temporellement se r√©partissent entre Train et Test faussant l'entra√Ænement. 
                En triant par date, les donn√©es de test et en ‚Äòsplitant‚Äô sur la fin du jeu de donn√©es, les donn√©es de Test sont vraiment "in√©dites" pour le mod√®le. 
                """)
    st.markdown(""" Avec **Random Forest**, **XGBoost** et **Prophet**, l‚Äôencodage n'apporte pas de b√©n√©fices majeurs par rapport √† une simple variable cat√©gorielle (ex. hour ou dayofweek). 
                De m√™me, la normalisation des donn√©es n‚Äôa pas d‚Äôimpact significatif sur la performance des mod√®les. Nous faisons le choix de laisser les variables sans normalisation et sans transformation variables cycliques.
            """)
    
    st.write('#### Fine tunning - Hyperparam√®tres ')
    st.write("Pour une approche plus m√©thodique dans la comparaison des 2 mod√®les bas√©s sur des arbres de d√©cisions et travailler avec les meilleurs param√®trages, " \
    "nous avons utilis√© **Grid Search**. Pour all√©ger le besoin de puissance de calcul demand√©s ci-apr√®s, nous laisserons laisserons les param√®tres suivants."
    "C'est un compromis entre une exigence de m√©moire acceptable pour ce projet streamlit en ligne et des score √©lev√©s des m√©triques observ√©es ")
    
    code = '''
            current_model = RandomForestRegressor(
                n_estimators=8, # Nombre d'arbres dans la for√™t. Plus il y en a, plus le mod√®le est robuste mais lent.
                max_depth=8, # Profondeur maximale de chaque arbre. Contr√¥le la complexit√© du mod√®le pour √©viter le surapprentissage.
                min_samples_split=2, # Nombre minimum d'√©chantillons requis pour diviser un n≈ìud interne.
                min_samples_leaf=1, # Nombre minimum d'√©chantillons requis pour qu'un n≈ìud soit une feuille.
                random_state=42, # Graine al√©atoire pour la reproductibilit√© des r√©sultats.
                n_jobs=1 # Utile pour Streamlit pour la performance

            current_model = XGBRegressor(
                n_estimators=100,    # Nombre d'estimateurs (arbres)
                max_depth=3,         # Profondeur maximale de l'arbre
                learning_rate=0.05,  # Taux d'apprentissage. R√©duit la contribution de chaque arbre pour rendre le mod√®le plus robuste.
                random_state=42,
                n_jobs=1 
            )
        '''
    st.code(code, language='python')

def lancement():
    # Bouton pour lancer le traitement des donn√©es et l'affichage
    if st.button("Charger et Traiter les Donn√©es"):
        with st.spinner("Chargement et traitement des donn√©es en cours..."):
            # Assignation directe √† 'df' et stockage sous la cl√© 'df' dans session_state
            df, split_date, target, features = load_process_dataset_modelisation() 
            
            st.session_state['df'] = df
            st.session_state['split_date'] = split_date
            st.session_state['target'] = target
            st.session_state['features'] = features
 
        st.success("Donn√©es charg√©es et pr√©trait√©es avec succ√®s !")
        
        st.subheader("Aper√ßu du DataFrame apr√®s pr√©traitement :")
        st.dataframe(st.session_state['df'].sample(10)) 
        
        st.subheader("Param√®tres de mod√©lisation :")
        st.write(f"**Date de s√©paration (split_date) :** {st.session_state['split_date']}")
        st.write(f"**Variable cible (target) :** `{st.session_state['target']}`")
        st.write(f"**Variables explicatives (features) :**")
        st.write(st.session_state['features'])

# --- AJOUT DES VISUALISATIONS ICI AVEC LA BONNE INDENTATION ---
        # Ces blocs s'ex√©cutent car nous sommes d√©j√† dans le if st.button(...)
        # et st.session_state['df'] vient d'√™tre d√©fini.
        st.markdown("---")
        st.subheader("Graphique 1: V√©rification de l'ordre temporel (Index vs. Position Ordinale)")
        # Assurez-vous que plot_date_order et plot_target_over_time_with_split sont d√©finies dans votre script
        # avant d'√™tre appel√©es ici.
        plot_date_order(st.session_state['df'], title="V√©rification de l'ordre temporel du DataFrame apr√®s pr√©traitement")

        st.markdown("---")
        st.subheader("Graphique 2: Visualisation de la Variable Cible et de la Date de S√©paration")
        plot_target_over_time_with_split(st.session_state['df'], 
                                          st.session_state['target'], 
                                          st.session_state['split_date'])
        # --- FIN DE L'AJOUT DES VISUALISATIONS ---

    # ======================================================================
    # Nouveau bouton pour entra√Æner RF et XGBoost ensemble
    # ======================================================================
    # V√©rifie si les donn√©es sont charg√©es avant d'afficher ce bouton
    if st.session_state['df'] is not None: 
        if st.button("Lancer l'entra√Ænement et l'√©valuation des mod√®les (RF & XGBoost)"):
            # R√©cup√©rer les donn√©es de session_state pour les passer √† la fonction RF_XGB
            df = st.session_state['df'] 
            split_date = st.session_state['split_date']
            target = st.session_state['target']
            features = st.session_state['features']

            # --- Entra√Ænement et √©valuation RandomForest ---
            with st.spinner("Entra√Ænement et √©valuation du mod√®le RandomForest en cours..."):
                # Appel de la fonction renomm√©e RF_XGB pour RandomForest
                rf_metrics_df_per_region, rf_global_mean_metrics = RF_XGB("RandomForest", df, split_date, target, features)
                
                st.session_state['rf_metrics_per_region'] = rf_metrics_df_per_region
                st.session_state['rf_global_mean_metrics'] = rf_global_mean_metrics
            st.success("√âvaluation RandomForest termin√©e !")
            
            st.markdown("---") # S√©parateur visuel entre les mod√®les

            # --- Entra√Ænement et √©valuation XGBoost ---
            with st.spinner("Entra√Ænement et √©valuation du mod√®le XGBoost en cours..."):
                # Appel de la fonction renomm√©e RF_XGB pour XGBoost
                xgb_metrics_df_per_region, xgb_global_mean_metrics = RF_XGB("XGBoost", df, split_date, target, features)

                st.session_state['xgb_metrics_per_region'] = xgb_metrics_df_per_region
                st.session_state['xgb_global_mean_metrics'] = xgb_global_mean_metrics
            st.success("√âvaluation XGBoost termin√©e !")
        
        # ======================================================================
        # Affichage s√©par√© des r√©sultats RF et XGBoost
        # Ces blocs s'ex√©cutent si les r√©sultats sont pr√©sents dans session_state
        # ======================================================================
        if st.session_state['rf_metrics_per_region'] is not None:
            st.subheader("Performances du mod√®le RandomForest par r√©gion :")
            st.dataframe(st.session_state['rf_metrics_per_region'].set_index('R√©gion').style.highlight_max(axis=0, subset=['R2 Score']).highlight_min(axis=0, subset=['Mean Absolute Error', 'MAPE (%)', 'Root Mean Squared Error', 'Bias']))

            st.subheader("Moyennes des m√©triques d'√©valuation RandomForest (Global) :")
            st.dataframe(st.session_state['rf_global_mean_metrics'].to_frame(name='Moyenne').T)

        if st.session_state['xgb_metrics_per_region'] is not None:
            st.markdown("---") 
            st.subheader("Performances du mod√®le XGBoost par r√©gion :")
            st.dataframe(st.session_state['xgb_metrics_per_region'].set_index('R√©gion').style.highlight_max(axis=0, subset=['R2 Score']).highlight_min(axis=0, subset=['Mean Absolute Error', 'MAPE (%)', 'Root Mean Squared Error', 'Bias']))

            st.subheader("Moyennes des m√©triques d'√©valuation XGBoost (Global) :")
            st.dataframe(st.session_state['xgb_global_mean_metrics'].to_frame(name='Moyenne').T)
    else:
        st.info("Cliquez sur 'Charger et Traiter les Donn√©es' pour commencer √† visualiser et mod√©liser. " \
        "L'entrainement des mod√®les est ensuite propos√©.")

@st.cache_data    
def load_process_dataset_modelisation():
    #T√©l√©charge et pr√©traite les donn√©es depuis Google Drive."""
    file_id = "1wiXdpj6XHzB1eRxRbvcnsgE21ukVBvXs"  # Ton ID de fichier extrait
    url = f"https://drive.google.com/uc?id={file_id}"  # Lien de t√©l√©chargement direct
    output = "COMPILATION_CONSO_TEMP_POP_2.csv"
    # Non reduced
    # https://drive.google.com/file/d/1wiXdpj6XHzB1eRxRbvcnsgE21ukVBvXs/view?usp=sharing
    #reduce : file_id = "1dunWvb7loR5kWYZwb8BX_lwmYMP0157q" // COMPILATION_CONSO_TEMP_POP_reduced.csv
    
    try:
        gdown.download(url, output, quiet=False)
    except Exception as e:
        st.error(f"Erreur lors du t√©l√©chargement du fichier : {e}")
        st.stop() 

    df= pd.read_csv(output, sep=';',low_memory=False)
    #on_bad_lines="skip", encoding="utf-8"
    
    # Filtrer les donn√©es temporelles pour se concentrer sur une p√©riode pertinente et enlever la Corse
    # Appliquez d'abord les filtres sur le DataFrame original
    df_filtered = df[(df['Date + Heure'] >= '2016-01-01') & 
                     (df['Date + Heure'] <= '2024-12-31') & 
                     (df['R√©gion'] != 'Corse')].copy() # Utilisez .copy() pour √©viter SettingWithCopyWarning

    # Convertir 'Date + Heure' en datetime et la d√©finir comme index pour le DataFrame filtr√©
    df_filtered['Date + Heure'] = pd.to_datetime(df_filtered['Date + Heure'], errors='coerce')
    df_filtered = df_filtered.set_index('Date + Heure')
    df_filtered = df_filtered.sort_index()

    # Le DataFrame final √† utiliser sera df_filtered
    df = df_filtered.copy() # On renomme df_filtered en df pour la coh√©rence avec le reste du code


    # Conversion en datetime DATE pour extractions 
    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d', errors='coerce')
    # Extraire les caract√©ristiques temporelles SUPPLEMENTAIRES √† partir de 'DATE'
    df['year'] = df['Date'].dt.year
    df['month'] = df['Date'].dt.month
    df['day_of_week'] = df['Date'].dt.dayofweek  # Lundi = 0, Dimanche = 6
    df['day_of_year'] = df['Date'].dt.dayofyear
    df['week_of_year'] = df['Date'].dt.isocalendar().week
    #df['PlageHoraire']= df['Heure']
    df['PlageHoraire']= df['Heure'].str[:2].astype(int) # Extraction de l'heure
    df = df.drop(columns=['Date', 'Heure', 'Date - Heure'])
    df = df.sort_index() #NOUVEAU

    # R√©cup√©rer toutes les colonnes du DataFrame
    all_columns = df.columns.tolist()

    # D√©finir la target (√† exclure des features)
    target = 'Consommation (MW)'

    # D√©finir une liste de colonnes √† exclure (en plus de la target)
    exclude_columns = ['R√©gion']

    # S√©lectionner les features en excluant la target et les colonnes √† exclure
    features = [col for col in all_columns if col != target and col not in exclude_columns]

    # D√©finir la proportion de l'ensemble de test
    #test_size = 0.20  # Pour 20%
    # Calculer la date de s√©paration
    #split_date = df.iloc[int(len(df) * (1 - test_size))].name
    # Afficher la date de s√©paration
    #print(f"Date de s√©paration pour {int(test_size * 100)}% de test : {split_date}")
    #split_date = "2021-09-06 00:00:00"

        # D√©finir la proportion de l'ensemble de test
    test_size = 0.20  # Cela signifie 20% des donn√©es pour le test, et donc 80% pour l'entra√Ænement.

    # Calculer le nombre d'observations total
    total_observations = len(df)

    # Calculer le nombre d'observations dans l'ensemble d'entra√Ænement (80%)
    train_observations = int(total_observations * (1 - test_size))

    # Calculer le nombre d'observations dans l'ensemble de test (20%)
    test_observations = total_observations - train_observations

    # Calculer la date de s√©paration en se basant sur la 80√®me percentile des observations
    # Le .name r√©cup√®re la valeur de l'index (qui est la date) de cette ligne
    split_date = df.iloc[train_observations - 1].name # Utilisez train_observations - 1 car iloc est 0-index√©

    # Afficher les informations de s√©paration pour justifier les volumes
    print(f"Volume total des entr√©es (observations) : {total_observations}")
    print(f"Proportion d'entra√Ænement d√©sir√©e : {int((1 - test_size) * 100)}%")
    print(f"Nombre d'observations pour l'entra√Ænement : {train_observations} lignes")
    print(f"Proportion de test d√©sir√©e : {int(test_size * 100)}%")
    print(f"Nombre d'observations pour le test : {test_observations} lignes")
    print(f"Date de s√©paration : {split_date}")

    return df, split_date, target, features


def RF_XGB(model_name, df, split_date, target, features):
    """
    Entra√Æne un mod√®le (RandomForest ou XGBoost) pour chaque r√©gion et √©value ses performances.
    Args:
        model_name (str): Nom du mod√®le √† entra√Æner ("RandomForest" ou "XGBoost").
        df (pd.DataFrame): DataFrame contenant les donn√©es pr√©trait√©es.
        split_date (datetime): Date de s√©paration pour les ensembles d'entra√Ænement/test.
        target (str): Nom de la colonne cible.
        features (list): Liste des noms des colonnes explicatives.
    Returns:
        tuple: DataFrame des m√©triques par r√©gion et Series des m√©triques moyennes globales.
    """
    results = []
    regions = df['R√©gion'].unique()

    # Diviser le DataFrame global en ensembles d'entra√Ænement et de test une seule fois
    train_df = df[df.index < split_date]
    test_df = df[df.index >= split_date]

    for region in regions:
        st.write(f"Entra√Ænement et √©valuation du mod√®le **{model_name}** pour la r√©gion : **{region}**") 
        
        # Filtrer les donn√©es par r√©gion √† partir des ensembles d√©j√† splitt√©s
        train_region_df = train_df[train_df['R√©gion'] == region]
        test_region_df = test_df[test_df['R√©gion'] == region]
            
        X_train = train_region_df[features]
        y_train = train_region_df[target]
        X_test = test_region_df[features]
        y_test = test_region_df[target]

        # =========================================
        # INSTANCIATION DU MOD√àLE + HYPERPARAM√àTRES
        # =========================================
        current_model = None
        if model_name == "RandomForest":
            current_model = RandomForestRegressor(
                n_estimators=8, # Nombre d'arbres dans la for√™t. Plus il y en a, plus le mod√®le est robuste mais lent.
                max_depth=8, # Profondeur maximale de chaque arbre. Contr√¥le la complexit√© du mod√®le pour √©viter le surapprentissage.
                min_samples_split=2, # Nombre minimum d'√©chantillons requis pour diviser un n≈ìud interne.
                min_samples_leaf=1, # Nombre minimum d'√©chantillons requis pour qu'un n≈ìud soit une feuille.
                random_state=42, # Graine al√©atoire pour la reproductibilit√© des r√©sultats.
                n_jobs=1 # Utile pour Streamlit pour la performance
            )
        elif model_name == "XGBoost":
            current_model = XGBRegressor(
                n_estimators=100,    # Nombre d'estimateurs (arbres)
                max_depth=3,         # Profondeur maximale de l'arbre
                learning_rate=0.05,  # Taux d'apprentissage. R√©duit la contribution de chaque arbre pour rendre le mod√®le plus robuste.
                random_state=42,
                n_jobs=1 
            )
        else:
            st.error(f"Mod√®le non support√© pour l'entra√Ænement : {model_name}")
            continue 
        
        current_model.fit(X_train, y_train)

        predictions = current_model.predict(X_test)
        
        # Calculer les m√©triques
        mse = mean_squared_error(y_test, predictions)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, predictions)
        mape = mean_absolute_percentage_error(y_test, predictions) * 100 
        r2 = r2_score(y_test, predictions)
        
        # Moyennes des valeurs r√©elles et pr√©dites
        mean_y_test = np.mean(y_test)
        mean_y_pred = np.mean(predictions) 
        # Calcul du Bias
        bias = mean_y_pred - mean_y_test

        result = {
            'R√©gion': region,
            'Moy y_test': mean_y_test,
            'Moy y_pred': mean_y_pred,
            'Bias': bias,
            'Mean Squared Error': mse,
            'Root Mean Squared Error': rmse,
            'Mean Absolute Error': mae,
            'MAPE (%)': mape, 
            'R2 Score': r2
        }
        
        # Ajouter les importances des features si le mod√®le le supporte
        if hasattr(current_model, 'feature_importances_'):
            for feature, importance in zip(X_train.columns, current_model.feature_importances_): 
                result[f'Importance {feature}'] = importance
        
        results.append(result)
        
    results_df = pd.DataFrame(results)
    
    # Calculer la moyenne des m√©triques globales (pour toutes les r√©gions)
    numeric_metrics_cols = ['R2 Score', 'Mean Squared Error', 'Root Mean Squared Error', 'Mean Absolute Error', 'MAPE (%)', 'Bias']
    mean_metrics = results_df[numeric_metrics_cols].mean()

    return results_df, mean_metrics



