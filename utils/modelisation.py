import streamlit as st
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns  
import datetime
import gdown

#Import des biblioth√®ques ML
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler

from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error

from sklearn.model_selection import TimeSeriesSplit
from sklearn.model_selection import GridSearchCV
from prophet import Prophet


def intro():
    if 'processed_df' not in st.session_state:
        st.session_state['processed_df'] = None
        st.session_state['split_date'] = None
        st.session_state['target'] = None
        st.session_state['features'] = None
        st.session_state['df_prophet_ready'] = None
        st.session_state['rf_metrics_per_region'] = None
        st.session_state['rf_global_mean_metrics'] = None

    st.write('## Classification du probl√®me üìÇ')

    st.write("");st.write("") 

    st.markdown(""" <u>Type de probl√®me et t√¢che de machine learning</u> : 
            Notre projet s‚Äôapparente √† de la **pr√©diction de valeurs continues dans une suite temporelle** pr√©sentant plusieurs saisonnalit√©s.
                L'objectif est d'anticiper la demande en √©nergie en fonction du temps, des conditions m√©t√©orologiques et d'autres facteurs exog√®nes.
                """,unsafe_allow_html=True)
    st.write('#### Choix des m√©triques de performance üéØ')
            
    st.markdown("""La m√©trique **MAPE (Mean Absolute Percentage Error)** est notre m√©trique principale car elle est facilement interpr√©table et comparable avec d‚Äôautres mod√®les.
                Nous cherchons d‚Äôune part √† p√©naliser les grandes erreurs compte tenu de l‚Äôenjeu de pr√©diction de consommation au plus juste (**RMSE** faible), 
                tout en pouvant comparer facilement nos diff√©rents mod√®les sur la base de % de variation (MAPE). Enfin, la qualit√© globale du mod√®le doit aussi √™tre √©lev√©e pour tenir compte de mani√®re √©quilibr√©e des sp√©cificit√©s r√©gionales (**Score R2**).""") 
    st.markdown("""
                Pour couvrir l‚Äôensemble des KPI pertinents sur ce probl√®me de r√©gression nous allons donc r√©cup√©rer chacun des indicateurs type :
                
                - Erreurs absolues et relatives (**MAE, MAPE**)
                - Erreurs quadratiques (**MSE, RMSE**)
                - Qualit√© d‚Äôajustement (**R¬≤ Score**)
                """)
    st.write('#### Choix des mod√®les Machine Learning ü§ñ ')
    st.markdown("""
                De fa√ßon plus limit√©e que le rapport d'√©tude, nous ne pr√©senterons ici que :

                - <span style="color:blue;">**Prophet**</span> : pour challenger notamment la d√©tection des saisonnalit√©s et la robustesse √† long terme.
                - <span style="color:blue;">**RandomForest**</span>, <span style="color:blue;">**XG Boost**</span> : 2 autres mod√®les, plus g√©n√©ralistes et simples √† entra√Æner

                Ces mod√®les sont connus pour bien g√©rer les s√©ries temporelles.
                """, unsafe_allow_html=True)
    st.write('#### Series temporelles ‚è≤Ô∏è ? Split= ‚ÄúHold Out‚Äù')
    st.markdown("""
                Objectif = √âviter la fuite de donn√©es. Si les donn√©es ne sont pas tri√©es par date et que le train_test_split est al√©atoire, 
                il est possible que des observations tr√®s proches temporellement se r√©partissent entre Train et Test faussant l'entra√Ænement. 
                En triant par date, les donn√©es de test et en ‚Äòsplitant‚Äô sur la fin du jeu de donn√©es, les donn√©es de Test sont vraiment "in√©dites" pour le mod√®le. 
                """)
    st.markdown(""" Avec **Random Forest**, **XGBoost** et **Prophet**, l‚Äôencodage n'apporte pas de b√©n√©fices majeurs par rapport √† une simple variable cat√©gorielle (ex. hour ou dayofweek). 
                De m√™me, la normalisation des donn√©es n‚Äôa pas d‚Äôimpact significatif sur la performance des mod√®les. Nous faisons le choix de laisser les variables sans normalisation et sans transformation variables cycliques.
            """)
    # Bouton pour lancer le traitement des donn√©es et l'affichage
    if st.button("Charger et Traiter les Donn√©es"):
        with st.spinner("Chargement et traitement des donn√©es en cours..."):
            # D√©composez le tuple retourn√© en variables s√©par√©es
            processed_df, split_date, target, features = load_process_dataset_modelisation() 
            # CES LIGNES SONT CRUCIALES POUR LE STOCKAGE
            st.session_state['processed_df'] = processed_df
            st.session_state['split_date'] = split_date
            st.session_state['target'] = target
            st.session_state['features'] = features
            st.session_state['df_prophet_ready'] = processed_df.reset_index().rename(columns={'Date + Heure': 'ds', 'Consommation (MW)': 'y'})
    # ...
        st.success("Donn√©es charg√©es et pr√©trait√©es avec succ√®s !")
        st.subheader("Aper√ßu du DataFrame apr√®s pr√©traitement :")
        st.dataframe(processed_df.sample(10)) 
        st.subheader("Param√®tres de mod√©lisation :")
        st.write(f"**Date de s√©paration (split_date) :** {split_date}")
        st.write(f"**Variable cible (target) :** `{target}`")
        st.write(f"**Variables explicatives (features) :**")
        st.write(features)


    if st.button("Lancer l'entra√Ænement et l'√©valuation RandomForest"):
        if 'processed_df' not in st.session_state:
            st.warning("Veuillez d'abord charger et traiter les donn√©es.")
        else:
            processed_df = st.session_state['processed_df']
            split_date = st.session_state['split_date']
            target = st.session_state['target']
            features = st.session_state['features']

            with st.spinner("Entra√Ænement et √©valuation des mod√®les RandomForest en cours..."):
                # Appel de la nouvelle fonction adapt√©e
                rf_metrics_df_per_region, rf_global_mean_metrics = random_forest (processed_df, split_date, target, features)

            st.success("√âvaluation RandomForest termin√©e !")

            st.subheader("Performances du mod√®le RandomForest par r√©gion :")
            # Affichage du DataFrame avec style
            st.dataframe(rf_metrics_df_per_region.set_index('R√©gion').style.highlight_max(axis=0, subset=['R2 Score']).highlight_min(axis=0, subset=['Mean Absolute Error', 'MAPE (%)', 'Root Mean Squared Error', 'Bias']))

            st.subheader("Moyennes des m√©triques d'√©valuation (Global) :")
            # Affichage des moyennes globales dans un petit tableau ou en texte
            st.dataframe(rf_global_mean_metrics.to_frame(name='Moyenne').T) # Pour afficher comme un tableau horizontal
            # Ou en texte :
            # for metric, value in rf_global_mean_metrics.items():
            #     st.write(f"**{metric}**: {value:.4f}")

            # Stocker les r√©sultats si vous voulez les utiliser ailleurs
            st.session_state['rf_metrics_per_region'] = rf_metrics_df_per_region
            st.session_state['rf_global_mean_metrics'] = rf_global_mean_metrics

    
def load_process_dataset_modelisation():
    #T√©l√©charge et pr√©traite les donn√©es depuis Google Drive."""
    file_id = "1wiXdpj6XHzB1eRxRbvcnsgE21ukVBvXs"  # Ton ID de fichier extrait
    url = f"https://drive.google.com/uc?id={file_id}"  # Lien de t√©l√©chargement direct
    output = "COMPILATION_CONSO_TEMP_POP_2.csv"
    gdown.download(url, output, quiet=False)
    df= pd.read_csv(output, sep=';', on_bad_lines="skip", encoding="utf-8",low_memory=False)
    
    # Filtrer les donn√©es temporelles pour se concentrer sur une p√©riode pertinente et enlever la Corse
    df_filtered = df[(df['Date + Heure'] >= '2016-01-01') & 
                    (df['Date + Heure'] <= '2024-12-31')& (df['R√©gion']!='Corse')] 

    # Identifier les lignes avec -0.00 dans les colonnes sp√©cifiques
    cols_to_check = ['TMoy (¬∞C)', 'TMin (¬∞C)', 'TMax (¬∞C)']
    neg_zero_mask = (df_filtered[cols_to_check] == -0.00)

    # Appliquer la correction uniquement aux valeurs identifi√©es en utilisant .loc
    df_filtered.loc[:, cols_to_check] = df_filtered.loc[:, cols_to_check].mask(neg_zero_mask, 0.00)

    # Remettre la colonne 'Date + Heure' en index
    df = df_filtered.set_index('Date + Heure')
    df.index = pd.to_datetime(df.index)

    # Conversion en datetime DATE pour extractions 
    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d', errors='coerce')
    # Extraire les caract√©ristiques temporelles SUPPLEMENTAIRES √† partir de 'DATE'
    df['year'] = df['Date'].dt.year
    df['month'] = df['Date'].dt.month
    df['day_of_week'] = df['Date'].dt.dayofweek  # Lundi = 0, Dimanche = 6
    df['day_of_year'] = df['Date'].dt.dayofyear
    df['week_of_year'] = df['Date'].dt.isocalendar().week
    df['PlageHoraire']= df['Heure'].str[:2].astype(int) # Extraction de l'heure
    df = df.drop(columns=['Date', 'Heure', 'Date - Heure'])

    # R√©cup√©rer toutes les colonnes du DataFrame
    all_columns = df.columns.tolist()

    # D√©finir la target (√† exclure des features)
    target = 'Consommation (MW)'

    # D√©finir une liste de colonnes √† exclure (en plus de la target)
    exclude_columns = ['R√©gion']

    # S√©lectionner les features en excluant la target et les colonnes √† exclure
    features = [col for col in all_columns if col != target and col not in exclude_columns]

    # D√©finir la proportion de l'ensemble de test
    test_size = 0.20  # Pour 20%
    # Calculer la date de s√©paration
    split_date = df.iloc[int(len(df) * (1 - test_size))].name
    # Afficher la date de s√©paration
    print(f"Date de s√©paration pour {int(test_size * 100)}% de test : {split_date}")

    return df, split_date, target, features



def random_forest (df, split_date, target, features):
    """
    Entra√Æne un mod√®le RandomForest pour chaque r√©gion, √©value ses performances
    et retourne un DataFrame des m√©triques, y compris les importances des features.
    """
    results = [] # Pour stocker les m√©triques par r√©gion
    # all_y_test_RF et all_y_pred_RF peuvent √™tre g√©r√©s ici si n√©cessaire pour des agr√©gations globales,
    # mais pour le tableau par r√©gion, ils ne sont pas directement n√©cessaires au retour.

    regions = df['R√©gion'].unique()

    # NOTE: Dans votre script original, vous refiltrez df_region = df[df['R√©gion'] == region]
    # puis vous faites le split sur df_region.index.
    # On peut optimiser en splittant le df global une fois, puis en filtrant par r√©gion.
    # Ou garder votre logique si elle est plus claire pour vous.
    # Je vais garder la logique que j'avais propos√©e qui splittait globalement puis filtrait,
    # car cela √©vite de recalculer split_date √† chaque it√©ration.

    # Diviser le DataFrame global en ensembles d'entra√Ænement et de test
    train_df = df[df.index < split_date]
    test_df = df[df.index >= split_date]

    for region in regions:
        # Affichage pour Streamlit, remplace votre print()
        st.write(f"Entra√Ænement et √©valuation pour la r√©gion : **{region}**") 
        
        # Filtrer les donn√©es par r√©gion √† partir des ensembles d√©j√† splitt√©s
        train_region_df = train_df[train_df['R√©gion'] == region]
        test_region_df = test_df[test_df['R√©gion'] == region]

        if len(train_region_df) == 0 or len(test_region_df) == 0:
            st.warning(f"Pas assez de donn√©es pour la r√©gion {region}. Skipping.")
            continue
            
        # Pr√©parer les donn√©es pour le mod√®le
        X_train = train_region_df[features]
        y_train = train_region_df[target]
        X_test = test_region_df[features]
        y_test = test_region_df[target]

        # Initialiser et entra√Æner le mod√®le RandomForest avec VOS hyperparam√®tres
        model = RandomForestRegressor(
            n_estimators=10, 
            max_depth=10, 
            min_samples_split=2, 
            min_samples_leaf=1, 
            random_state=42,
            n_jobs=-1 # Utile pour Streamlit pour la performance
        )
        model.fit(X_train, y_train)

        # Faire des pr√©dictions
        predictions = model.predict(X_test)

        # all_y_test_RF et all_y_pred_RF pourraient √™tre agr√©g√©s ici si vous avez besoin des m√©triques globales
        # pour TOUTES les r√©gions combin√©es √† la fin. Pour le tableau par r√©gion, ce n'est pas n√©cessaire.
        
        # Calculer les m√©triques
        mse = mean_squared_error(y_test, predictions)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, predictions)
        mape = mean_absolute_percentage_error(y_test, predictions) * 100 # Multiplier par 100 pour un %
        r2 = r2_score(y_test, predictions)
        
        # Moyennes des valeurs r√©elles et pr√©dites
        mean_y_test = np.mean(y_test)
        mean_y_pred = np.mean(predictions) # C'est 'predictions' ici
        # Calcul du Bias
        bias = mean_y_pred - mean_y_test

        result = {
            'R√©gion': region,
            'Moy y_test': mean_y_test,
            'Moy y_pred': mean_y_pred,
            'Bias': bias,
            'Mean Squared Error': mse,
            'Root Mean Squared Error': rmse,
            'Mean Absolute Error': mae,
            'MAPE (%)': mape, # Renomm√© pour correspondre au %
            'R2 Score': r2
        }
        
        # Ajouter les importances des features
        for feature, importance in zip(X_train.columns, model.feature_importances_): # Utilisez X_train.columns
            result[f'Importance {feature}'] = importance
        
        results.append(result)
        
        # Les print() sont remplac√©s par st.write() si vous voulez des affichages interm√©diaires par r√©gion
        # Mais un tableau final est g√©n√©ralement pr√©f√©r√© dans Streamlit.

    results_df = pd.DataFrame(results)
    
    # Calculer la moyenne des m√©triques globales (pour toutes les r√©gions)
    # Assurez-vous que les colonnes existent et sont num√©riques
    numeric_metrics_cols = ['R2 Score', 'Mean Squared Error', 'Root Mean Squared Error', 'Mean Absolute Error', 'MAPE (%)', 'Bias']
    mean_metrics = results_df[numeric_metrics_cols].mean()

    return results_df, mean_metrics # Retourne le DF par r√©gion et les moyennes globales
    